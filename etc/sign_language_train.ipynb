{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyPltYwirgxQ2hHW7SJbnfEf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jNbawRbIFjPW"},"outputs":[],"source":["import numpy as np\n","import os\n","\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"]},{"cell_type":"code","source":["# actions = [\n","#     '안녕하세요',\n","#     '만나다',\n","#     '반갑다'\n","# ]\n","\n","\n","# 로컬\n","# from google.colab import files\n","# uploaded = files.upload()\n","\n","# 구글 드라이브\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data = np.concatenate([\n","    np.load('/content/drive/MyDrive/Colab_Test/total_dataset.npy'),\n","], axis=0)\n","\n","data.shape\n","\n","# 훈련 실험할 값들\n","# data1, data2, data3 = data[:, :, :84], data[:,:,99:183], data[:,:,-1:]\n","# print(\"1: \", data1.shape)\n","# print(\"2: \", data2.shape)\n","# print(\"3: \", data3.shape)\n","\n","# data_ = np.concatenate((data1, data2, data3), axis=2)\n","# print(data_.shape)"],"metadata":{"id":"KoVrTgUMFoZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_data = data[:, :, :-1]\n","labels = data[:, 0, -1]\n","\n","print(x_data.shape)\n","print(labels.shape) # 라벨의 원핫 인코딩 필요\n","\n","label_length = len(list(set(labels)))\n","print(label_length)\n","\n","# print('\\n수어 인덱스')\n","# idxes = {}\n","# for i in labels:\n","#     if i not in idxes:\n","#         idxes[i] = True\n","#         print(i)"],"metadata":{"id":"PhyzCQQ1FrHK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 원핫 인코딩\n","# ex\n","# 0 [1, 0, 0]\n","# 1 [0, 1, 0]\n","# 2 [0, 0, 1]\n","\n","from tensorflow.keras.utils import to_categorical\n","\n","y_data = to_categorical(labels, num_classes=label_length)\n","y_data.shape"],"metadata":{"id":"oXCNa88ZFtYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터를 학습(train)과 검증(validation) 세트로 나눔 -> 모델의 성능을 평가 && 과적합 방지\n","# 과적합: 데이터 크기 작을 때 || 단일 샘플 데이터 세트 장기간 훈련\n","# x: 입력, y: 출력\n","from sklearn.model_selection import train_test_split\n","\n","x_data = x_data.astype(np.float32)\n","y_data = y_data.astype(np.float32)\n","\n","x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2024) # test_size 조정\n","\n","print(x_train.shape, y_train.shape)\n","print(x_val.shape, y_val.shape)"],"metadata":{"id":"CyuMgNysFvz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 구조 정의, 컴파일\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# model = Sequential([\n","#     LSTM(64, activation='relu', input_shape=x_train.shape[1:3]), # (512,30,198)[1:3] => (30,198): (시퀀스 길이, 특징 수)\n","#     Dense(32, activation='relu'),\n","#     Dense(len(actions), activation='softmax')\n","# ])\n","# model = Sequential([\n","#     Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=x_train.shape[1:]), # Convolutional layer 추가\n","#     MaxPooling1D(pool_size=2),  # MaxPooling layer 추가\n","#     LSTM(64, activation='relu'), # LSTM layer 유지\n","#     Dropout(0.2),  # Dropout layer 추가\n","#     Dense(64, activation='relu'), # Dense layer\n","#     Dropout(0.3),  # Dropout layer 추가\n","#     Dense(64, activation='relu'), # Dense layer 추가\n","#     Dense(len(actions), activation='softmax')  # Output layer 유지\n","# ])\n","from tensorflow.keras.layers import BatchNormalization\n","\n","# model = Sequential([\n","#     LSTM(64, activation='relu', input_shape=x_train.shape[1:3]), # (512,30,198)[1:3] => (30,198): (시퀀스 길이, 특징 수)\n","#     Dense(64, activation='relu'), # Dense layer\n","#     Dropout(0.3),  # Dropout layer 추가\n","#     Dense(64, activation='relu'), # Dense layer\n","#     Dense(32, activation='relu'), # Dense layer\n","#     Dropout(0.3),  # Dropout layer 추가\n","#     Dense(64, activation='relu'), # Dense layer\n","#     Dense(64, activation='relu'), # Dense layer\n","#     Dense(64, activation='relu'), # Dense layer 추가\n","#     Dense(len(actions), activation='softmax')  # Output layer 유지\n","# ])\n","model = Sequential([\n","    # Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', input_shape=x_train.shape[1:]), # Convolutional layer 추가\n","    # MaxPooling1D(pool_size=2),  # MaxPooling layer 추가\n","    # LSTM(64, activation='relu'), # LSTM layer 유지\n","    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]), # (512,30,198)[1:3] => (30,198): (시퀀스 길이, 특징 수)\n","\n","    # Dropout(0.4),  # Dropout layer 추가\n","    # BatchNormalization(),  # Batch Normalization 레이어 추가\n","    Dense(64, activation='relu'), # Dense layer\n","    Dense(64, activation='relu'), # Dense layer\n","    Dropout(0.3),  # Dropout layer 추가\n","    Dense(64, activation='relu'), # Dense layer\n","    Dense(64, activation='relu'), # Dense layer\n","    Dense(64, activation='relu'), # Dense layer\n","    Dropout(0.3),  # Dropout layer 추가\n","    # BatchNormalization(),  # Batch Normalization 레이어 추가\n","    Dense(64, activation='relu'), # Dense layer 추가\n","    Dense(label_length, activation='softmax')  # Output layer 유지\n","])\n","# optimizer = Adam(learning_rate=0.001) # 학습률을 설정?\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","model.summary()"],"metadata":{"id":"iYv022avFxtd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련 (epochs=200: 학습량)\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.models import load_model\n","\n","history = model.fit(\n","    x_train,\n","    y_train,\n","    validation_data=(x_val, y_val),\n","    epochs=20,\n","    callbacks=[\n","        ModelCheckpoint('model_ko.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n","        ReduceLROnPlateau(monitor='val_acc', factor=0.4, patience=10, verbose=1, mode='auto')\n","    ]\n",")"],"metadata":{"id":"GakQcCvTFzpC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 훈련 과정에서 발생한 손실(loss) 및 정확도(accuracy)를 시각화\n","# Adam 값 조정, 모델 계층 조정\n","import matplotlib.pyplot as plt\n","\n","fig, loss_ax = plt.subplots(figsize=(16, 10))\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(history.history['loss'], 'y', label='train loss') #노랑: 학습 데이터셋 기반 모델의 손실\n","loss_ax.plot(history.history['val_loss'], 'r', label='val loss') #빨강: 검증 데이터셋 기반 모델의 손실\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","loss_ax.legend(loc='upper left')\n","\n","acc_ax.plot(history.history['acc'], 'b', label='train acc') # 파랑: 학습 데이터셋 기반 모델 정확도\n","acc_ax.plot(history.history['val_acc'], 'g', label='val acc') #녹색: 검증 데이터셋 기반 모델 정확도\n","acc_ax.set_ylabel('accuracy')\n","acc_ax.legend(loc='upper left')\n","\n","plt.show()"],"metadata":{"id":"iRp7mVrrF1mL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델의 예측 결과와 실제 레이블 간의 다중 레이블 혼동 행렬(multilabel confusion matrix)을 계산하는 작업을 수행\n","\n","from sklearn.metrics import multilabel_confusion_matrix\n","\n","\n","y_pred = model.predict(x_val)\n","\n","multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))\n","\n","# 실행 결과 예시\n","# WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n","# array([[[94,  1],\n","#         [ 0, 34]],\n","\n","#        [[81,  0],\n","#         [ 0, 47]],\n","\n","#        [[81,  0],\n","#         [ 0, 47]]])\n","\n","# 예시로 해석\n","# True Positive (TP): 모델이 양성(Positive)으로 예측한 것 중에서 실제로 양성인 경우의 수. (94)\n","# True Negative (TN): 모델이 음성(Negative)으로 예측한 것 중에서 실제로 음성인 경우의 수. (34))\n","# False Positive (FP): 모델이 양성(Positive)으로 잘못 예측한 것 중에서 실제로는 음성인 경우의 수. (0: 모델이 양성으로 잘못 예측한 경우가 없음)\n","# False Negative (FN): 모델이 음성(Negative)으로 잘못 예측한 것 중에서 실제로는 양성인 경우의 수. (1)"],"metadata":{"id":"aY3jlLKnF3hl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# print(tf.__version__)"],"metadata":{"id":"3iuXaYdDF5Y5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P_9pjdCRhgbe"},"execution_count":null,"outputs":[]}]}